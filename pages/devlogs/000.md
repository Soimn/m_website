$
title: The First Devlog
date: 2022.03.20
$
The title of this devlog may be a bit deceiving, as this log was not written before starting, or anywhere near the start of, the project. This iteration of the project began in November 2021, and the compiler for the language has been completed up to, but not including, iterative type checking. The reason I say 'this' iteration, is that the project has been rebooted countless times since the first iteration in 2019, and is going to undergo another reboot during this devlog. So, in a sense, this is the last devlog for the previous iteration, as well as the first for the new iteration.


## Project history and Approach
The set of goals has varied for each iteration, some more than others. At first, the main goal was to create a C compiler with metaprogramming capabilities similar to Jai. This proved out to be difficult, as parsing C is a horrible experience, and modifying its grammar to support multiple return values, type inference and other shenanigans made it way worse. Some later iteration scrapped the C syntax, in favor of a syntax similar to Odin/Jai, and then the main goal was to make metaprogramming maximally powerful. This, in my mind, implied that the language should be made as simple as possible, such that metaprogramming only had to deal with its own complexity, and not some arbitrary cruft in the language design. However, this ended up getting out of hand, making the language concepts deviate too much from what actually runs on hardware. The next iteration then focused on making every decision grounded in reality, by examining a selection of target systems, and trying to construct a common model. From the selection of hardware I made, this became a rat's nest of complexity. Trying to learn from my mistakes, the last iteration made focused on making a simple bare-bones prototype of something I thought would work, and then evaluating and iterating upon that prototype. This is kind of the most obvious tactic to solving a problem, since you never truly know how it should be solved before actually solving it. I always knew this, but I kept thinking I wanted to avoid the common mistake in software of making something that seems to work, and then bunching on a ton of complexity to handle new features and fix bugs. The way I thought was the correct way of avoiding this was to thoroughly examine the problem and design everything neatly to solve that specific problem. However, as previously stated, you never truly know how a problem should be solved before actually solving it, which ended biting me hard. I kept on wasting way too much time on planning, afraid of writing something ad hoc that works, since it might not be the optimal solution I was looking for. Which is kind of weird, since I am not afraid of rewriting everything, as I have countless times (in total I have pushed 89 thousand lines of code to github, and removed 76 thousand, over the course of three iterations). What I should have learned is that the problem of tacking on complexity and making a mess, doesn't come from not planning enough, it comes from not discarding prototypes, and building upon them instead. Since I am clearly not afraid of scrapping everything, as opposed to some project manager in a company, I should leverage this, and stop "overplanning". The next iteration of the project will therefore prioritize making quick prototypes, instead of simulating a design committee with choice paralysis.

## Foundation
Now that the general development approach has been decided, what is it that I will be making? This seems like a weird question, since this is clearly a project devoted to making a programming language and compiler. However, making a programming language is not a very specific goal, as it leaves a bunch of questions like is it compiled or interpreted, is it object oriented or maybe functional, and generally what is actually accomplished by making yet another random programming language? To answer some of these questions, I will be taking a step back and evaluate what a programming language should be, what I want to accomplish by making one and what a programming language even is to begin with.

### What is a programming language?
According to the Wikipedia page on the [history of programming languages](https://en.wikipedia.org/wiki/History_of_programming_languages)
```
"It was eventually realized that programming in assembly language required a great deal of intellectual effort"
```
Which seems to imply that the reason programming languages came about was that programming in assembly was too hard, and that an easier way of programming computers would come in the form of programming languages. Viewed in a positive light, this statement seems like it makes sense, and would sort of imply that programming languages are a superior lossless representation of machine code that is easier understood by humans. However, when you think about how quality software is made today, a lot of it comes down to having fine grain control of what the computer does. Which, in my mind, is not very far away from programming in assembly. So in short, making software using programming languages is superior to assembly, except for when you want to make software of high quality. Then why was programming in assembly viewed as a problem, when it seems like assembly clearly is useful for some parts of programming?

#### Control
In my opinion, it all comes down to control. Assembly tends to offer the programmer more control than other programming languages. Control over where values live and which operations are used (to an extent, since machine code has become more of a suggestion to modern processors, as opposed to a list of strict instructions). This control gives a programmer the power needed to optimize routines, and crank out every single drop of that sweet sweet performance juice (one could argue this is also possible with intrinsics, however they are even more of a suggestion than assembly). However, this control also comes with a responsibility, a responsibility to utilize the computing resources effectively. With a higher level programming language, this responsibility is often shifted more towards the language, which makes easier to write non optimal programs that still run relatively efficiently. This is essentially the advantage of programming languages, they allow you to gain ease of use in exchange for control. 


#### "Zero Cost Abstractions"
When people talk about so-called "zero cost abstractions", they often try to explain why a certain language construct abstracts away a bunch of complexity, and allows a programmer to express logic in simpler terms, while still keeping the "performance" of writing it all out in assembly. This is basically never true, "zero cost abstractions" always lose something, since that is what it means to abstract *away* something. Abstraction will always reduce control. Even "trivial abstractions" such as replacing opcodes with mnemonics reduces control. Now the programmer cannot reason about the relative order of instructions given by their opcode's value without looking up the value for each mnemonic and breaking the abstraction. This might seem like a silly example, as knowing the relative order of instructions by their opcode seems useless, and mnemonics are surely easier to remember than a string of digits. However, knowing the opcode for each instruction is incredibly useful when writing self modifying code. This nicely illustrates the point that abstraction is always at the loss of something, and also leads up to the next point.


#### Breaking Abstractions
So far it would seem like every programmer is stuck with a choice between not having enough control to write optimal software, and too much control with not enough skill, or experience, to properly utilize it. However, this is not the only option. The previous paragraph may have made breaking the "instruction mnemonic" abstraction seem like something bad, but this might actually be the best solution we have. Surely writing software with maximal control would be the optimal solution for an all-knowing intelligence. However, as humans are famously bad at always making optimal decisions, programming with maximal control may not be the best solution. The obvious answer to this would be mixing levels of abstractions when it is deemed necessary. This would allow programming at the "lowest level" of abstraction the programmer is confident in, while still keeping the option for maximal control when deemed necessary. While sounding wonderful, this introduces a whole new class of problems relating to cooperation between layers of abstraction, as an assembly routine is useless if it cannot read the value of its parameters, due to them "being stuck at a higher level of abstraction".

#### Programming languages
At this point, a somewhat useful definition of a programming language can be formed.
```
A programming language is an, often multi-layered, abstraction of machine code
```
Which is obvious, but what is useful about this definition is that is illustrates a problem with most languages, namely that it is an **abstraction**. By being an abstraction, every language will therefore inherit the problem of managing control. Despite this being a glaring problem, when the goal is to write optimal software, it would seem like languages these days are praised for their abstractions. From the object-oriented languages such as Java, to scripting languages like Python, they are all praised for their "ease of use", and accompanying implied ease of writing robust and secure software. This is just absurd, as what people are basically saying is that these languages make software easier to write, more robust and secure, by allowing the programmer not to care how the program works. Which is kind of bonkers, because how would we know that the program is actually more robust and secure if nobody knows how it actually works. And if someone does know how it works, and can vouch for these claims, why couldn't they write it instead, as they clearly know more about the program than the actual programmers who wrote it. What these languages offer is an unbreakable (mostly) high level abstraction of machine code, and if you agree with the previous paragraph, this is obviously a stupid design if writing optimal software is the goal. However, you still have to remember how we got here, which was initially by quoting Wikipedia stating that assembly is often too hard to work with. Then for a programming language to be a useful concept, I would propose the following: 
```
A programming language should be an arbitrarily high stack of abstractions over machine code that the programmer is in full control over, and allows them to seamlessly transition from one layer to another
```
Programming languages should therefore not restrict the programmer to an arbitrary level of abstraction, but rather provide the tools to build abstractions over the lowest possible level.

### Metaprogramming

## The First Step